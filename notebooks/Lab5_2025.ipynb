{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPbtmfqMqsVj"
   },
   "source": [
    "# Function approximation with a deep neural network\n",
    "\n",
    "> Author : Badr TAJINI - Machine Learning 2 & Deep learning - ECE 2025-2026\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA-dG5TvNT9U"
   },
   "source": [
    "## Quartic function and training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze4-03KGq2Gx"
   },
   "source": [
    "In algebra, a quartic function is a function of the form\n",
    "$$\n",
    "f(t)=at^{4}+bt^{3}+ct^{2}+dt+e,\n",
    "$$\n",
    "where $a$ is nonzero, which is defined by a polynomial of degree four, called a quartic polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2459,
     "status": "ok",
     "timestamp": 1667396789070,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "XSxuWuabouDj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYRSPAtGouDo"
   },
   "source": [
    "Define and plot a quartic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1667396789072,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "JhCmQNviouDu"
   },
   "outputs": [],
   "source": [
    "D_in = 1\n",
    "D_out = 1\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.arange(-9,3.5,0.1).view(-1,1) #(-5,3.5,0.1)\n",
    "y = x**4 + 2*x**3 - 12*x**2 -2*x + 6\n",
    "y = torch.where(x < -5, torch.zeros_like(x), y)\n",
    "N = x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1667396789074,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "8Upa4fCuouD5",
    "outputId": "b8b6fdc6-3e58-4a47-9b34-ab438920bc7c"
   },
   "outputs": [],
   "source": [
    "print(x.size())\n",
    "print(y.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY7bxmOpsRYq"
   },
   "source": [
    "Converting Torch Tensor to NumPy Array for plotting the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1667396790103,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "L80Arv5FuLj-",
    "outputId": "174f8d12-82ae-409c-eb49-5e51be8c6686"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(x.numpy(), y.numpy(),'r-',label='Quartic function')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.show()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vI35l73mNZ0w"
   },
   "source": [
    "## Approximation with a deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tJWe_-W1khM"
   },
   "source": [
    "### Question: code a deep neural network to approximate the function. The network will have 3 full-connected layers (followed by a ReLU activation function) and a final full-connected layer without any activation function. You will use the Adam optimizer. Choose the most appropriate loss function. You must compute the loss at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6385,
     "status": "ok",
     "timestamp": 1667397711677,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "IWija8I3ouDy",
    "outputId": "2bb0c508-930c-4c8a-b424-7ef265d135b3"
   },
   "outputs": [],
   "source": [
    "# Complete this cell: model and training\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# create 3 hidden layers\n",
    "H1 = 30\n",
    "H2 = 20\n",
    "H3 = 10\n",
    "\n",
    "#**** Number of iterations (Niter) # set the checkpoint (np)\n",
    "Niter = 5*10**3\n",
    "saveLoss = np.zeros(Niter)\n",
    "\n",
    "# create a simple NN with 3 hidden layers and torch.NN\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H2, H3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H3, D_out)\n",
    ")\n",
    "\n",
    "# call torch.nn.MSE()\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# call LR = set by yourself\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# call optim torch.optim.adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# call the loop (Niter)\n",
    "for t in range(Niter):\n",
    "\n",
    "  # set the forward pass\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # compute the loss \n",
    "  loss = loss_fn(y_pred, y)\n",
    "  # checkpoint\n",
    "  saveLoss[t] = loss.detach().numpy()\n",
    "  if t % 1000 == 999:\n",
    "    print(t, loss.item())\n",
    "  # call optimizer\n",
    "  optimizer.zero_grad()\n",
    "  # call backward\n",
    "  loss.backward()\n",
    "  # call optmizer step\n",
    "  optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW-RbXaP2OrE"
   },
   "source": [
    "Plot the training error as a function of the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1667397733504,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "aam3YN7VouD-",
    "outputId": "1b68fbec-511a-42e2-b57d-45ac99e0089a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(range(Niter),saveLoss,'b-',label='Training error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnjcbWrJ0CV3"
   },
   "source": [
    "### Question: plot on the same graph the quartic function and its approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1667397883704,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "AnvnNn-touEB",
    "outputId": "b4b1e627-90ab-4c7d-88ff-2b2375b6f943",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model(x)\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x.numpy(), y.numpy(),'r-',label='Quartic function')\n",
    "plt.plot(x.numpy(), y_pred.detach().numpy(),'bo-',label='Deep approximation')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MpXhTY1rwGE"
   },
   "source": [
    "How many parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1667397902821,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "OhpZsJxeouD1"
   },
   "outputs": [],
   "source": [
    "# Function to count the number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1667397907799,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "xsEJhkeUr107",
    "outputId": "7b1b192f-f2fb-4ead-9da9-2f6b1f551fcd"
   },
   "outputs": [],
   "source": [
    "print(model.parameters)\n",
    "print(\"\\nTotal number of parameters {}\\n\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRKKUiGMMAGL"
   },
   "source": [
    "Print all the parameters (just for seeing them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1667397949846,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "hstPktpFLuYl",
    "outputId": "a055344c-6d4e-4bdf-a5e3-78c061a8b39f"
   },
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbEXUwJZNgX9"
   },
   "source": [
    "## Approximation with a shallow neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwoSChjz2fuE"
   },
   "source": [
    "### Question: code a one-hidden layer neural network with approximatively the same number of parameters than the multilayer neural network. What is the \"best\" architecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23183,
     "status": "ok",
     "timestamp": 1667398772902,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "Qw_JwF-42set",
    "outputId": "a07141df-eeec-4df5-c86c-62229bb9ae61"
   },
   "outputs": [],
   "source": [
    "# Complete this cell: model and training\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# create 3 hidden layers\n",
    "H1 = 300\n",
    "\n",
    "#**** Number of iterations (Niter) # set the checkpoint (np)\n",
    "Niter = 30*10**3\n",
    "saveLoss = np.zeros(Niter)\n",
    "\n",
    "# create a simple NN with 1 hidden layers and torch.NN\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H1, D_out)\n",
    ")\n",
    "\n",
    "# call torch.nn.MSE()\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# call LR = set by yourself\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# call optim torch.optim.adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# call the loop (Niter)\n",
    "for t in range(Niter):\n",
    "\n",
    "  # set the forward pass\n",
    "  y_pred = model(x)\n",
    "\n",
    "  # compute the loss \n",
    "  loss = loss_fn(y_pred, y)\n",
    "  # checkpoint\n",
    "  saveLoss[t] = loss.detach().numpy()\n",
    "  if t % 1000 == 999:\n",
    "    print(t, loss.item())\n",
    "  # call optimizer\n",
    "  optimizer.zero_grad()\n",
    "  # call backward\n",
    "  loss.backward()\n",
    "  # call optmizer step\n",
    "  optimizer.step()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1667398783967,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "fY4nUy-13H1e",
    "outputId": "159737ef-e93f-440a-9a5f-6035006b62d8"
   },
   "outputs": [],
   "source": [
    "y_pred = model(x)\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x.numpy(), y.numpy(),'r-',label='Quartic function')\n",
    "plt.plot(x.numpy(), y_pred.detach().numpy(),'bo-',label='Deep approximation')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1667398390712,
     "user": {
      "displayName": "Badr Tajini",
      "userId": "13878391745036494967"
     },
     "user_tz": -60
    },
    "id": "oaIZaCpV3Az9",
    "outputId": "48d6e8bf-6ab6-4837-f1d6-e8983a28ac2c"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTotal number of parameters {}\\n\".format(count_parameters(model)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
